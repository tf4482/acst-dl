# Acast Downloader (acst-dl)

A Python script for downloading HTML content from podcast feeds and extracting MP3 links. Specifically designed for Acast podcast feeds, this tool can download podcast episodes and organize them into structured directories with intelligent duplicate detection.

## Features

- ğŸ“¥ Download HTML content from multiple URLs
- ğŸµ Extract MP3 links from downloaded HTML pages
- ğŸ“ Organize downloads into named subdirectories
- ğŸ” **Hash-based duplicate detection** (prevents re-downloading same files)
- âš¡ Configurable download limits and timeouts
- ğŸ§¹ Automatic cleanup of temporary files
- ğŸ“Š Detailed download statistics and progress tracking
- ğŸ¨ Rich emoji-enhanced console output
- â³ Single-line progress indicators
- ğŸ”„ Support for both old list format and new dictionary format URLs

## Installation

### Prerequisites

- Python 3.8 or higher
- Poetry (recommended) or pip

### Using Poetry (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd acst-dl

# Install dependencies
poetry install

# Activate the virtual environment
poetry shell
```

### Using pip

```bash
# Clone the repository
git clone <repository-url>
cd acst-dl

# Install dependencies
pip install requests beautifulsoup4
```

## Configuration

Create or modify the [`acst-dl-config.json`](acst-dl-config.json) file to configure your downloads:

```json
{
  "urls": {
    "Podcast Name 1": "https://feeds.acast.com/public/shows/podcast-name-1",
    "Podcast Name 2": "https://feeds.acast.com/public/shows/podcast-name-2"
  },
  "output_directory": "~/data/podcasts",
  "timeout": 30,
  "max_mp3_links": 5,
  "download_mp3_files": true
}
```

**Note**: Hash-based duplicate detection is now enabled by default and requires no configuration.

### Configuration Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `urls` | Object/Array | Required | Dictionary of named URLs or array of URLs to process |
| `output_directory` | String | `"downloads"` | Directory where files will be saved |
| `timeout` | Number | `30` | Request timeout in seconds |
| `max_mp3_links` | Number | `null` | Maximum number of MP3 links to extract per URL |
| `download_mp3_files` | Boolean | `false` | Whether to download actual MP3 files |

### Hash-Based Duplicate Detection

The script now automatically prevents downloading duplicate MP3 files by:
- ğŸ” **Generating unique filenames** using MD5 hash of the URL (e.g., `media_43e4489f.mp3`)
- ğŸ“ **Checking file existence** before downloading
- âš¡ **Skipping duplicates** automatically without any configuration needed
- ğŸ¯ **No database required** - uses simple filename-based detection

## Usage

### Basic Usage

```bash
python acst-dl.py
```

The script will:
1. Read configuration from [`acst-dl-config.json`](acst-dl-config.json)
2. Create output directories as needed
3. Download HTML content from each configured URL
4. Extract MP3 links from the downloaded content
5. Optionally download the MP3 files themselves

### Output Structure

```
output_directory/
â”œâ”€â”€ Podcast Name 1/
â”‚   â””â”€â”€ media_43e4489f.mp3 (hash-based filename)
â”‚   â””â”€â”€ media_7ac9803d.mp3 (hash-based filename)
â””â”€â”€ Podcast Name 2/
    â””â”€â”€ media_20830c0e.mp3 (hash-based filename)
    â””â”€â”€ media_32758bac.mp3 (hash-based filename)
```

**Note**: Temporary HTML and MP3 links files are automatically cleaned up after successful downloads.

## Features in Detail

### Hash-Based Duplicate Detection ğŸ”

The script automatically prevents downloading duplicate files by:
- **URL-based hashing**: Each MP3 URL generates a unique MD5 hash
- **Smart filename generation**: Files are named `{base_name}_{hash}.mp3`
- **Instant duplicate detection**: Same URLs always produce the same filename
- **No configuration needed**: Works automatically without any setup
- **Bandwidth savings**: Skips re-downloading identical content
- **Storage efficiency**: Prevents duplicate files from consuming disk space

### MP3 Link Extraction ğŸµ

The script uses multiple methods to find MP3 links:
- Parses HTML elements (`<a>`, `<audio>`, `<source>` tags)
- Uses regex patterns to find direct MP3 URLs
- Maintains order of appearance in the original HTML
- Supports configurable limits on number of links extracted

### File Management ğŸ“

- **Automatic cleanup**: Always removes temporary HTML and link files when MP3 downloading is enabled
- **Hash-based duplicate prevention**: Intelligent detection using URL hashes
- **Single-line progress tracking**: Clean progress display for large files
- **Rich console output**: Emoji-enhanced feedback for better user experience

### Error Handling âŒ

- Comprehensive error handling for network issues
- Graceful handling of malformed URLs or HTML
- Detailed error reporting with emoji indicators
- Continues processing remaining URLs even if some fail

## Dependencies

- [`requests`](https://pypi.org/project/requests/) - HTTP library for downloading content
- [`beautifulsoup4`](https://pypi.org/project/beautifulsoup4/) - HTML parsing library
- [`pyinstaller`](https://pypi.org/project/pyinstaller/) - For creating standalone executables

## Examples

### Extract Links Only

```json
{
  "urls": {
    "My Podcast": "https://feeds.acast.com/public/shows/my-podcast"
  },
  "output_directory": "./podcast_links",
  "download_mp3_files": false,
  "max_mp3_links": 10
}
```

### Download Latest Episodes with Duplicate Detection

```json
{
  "urls": {
    "Daily News": "https://feeds.acast.com/public/shows/daily-news"
  },
  "output_directory": "~/Downloads/podcasts",
  "download_mp3_files": true,
  "max_mp3_links": 3,
  "timeout": 60
}
```

**Note**: Hash-based duplicate detection is automatically enabled when `download_mp3_files` is `true`.

### Backward Compatibility

The script supports the old array format for URLs:

```json
{
  "urls": [
    "https://feeds.acast.com/public/shows/podcast-1",
    "https://feeds.acast.com/public/shows/podcast-2"
  ]
}
```

## Building Standalone Executable

Use PyInstaller to create a standalone executable:

```bash
pyinstaller --onefile acst-dl.py
```

## License

This project is licensed under the MIT License - see the [`LICENSE`](LICENSE) file for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## Troubleshooting

### Common Issues

**Config file not found**: Ensure [`acst-dl-config.json`](acst-dl-config.json) exists in the same directory as the script.

**Permission errors**: Check that the output directory is writable and you have sufficient permissions.

**Network timeouts**: Increase the `timeout` value in the configuration for slow connections.

**No MP3 links found**: Some podcast feeds may use different formats or require authentication.

**Duplicate detection**: Files with the same URL will always generate the same hash-based filename, preventing re-downloads.

### Console Output

The script provides rich emoji-enhanced output including:
- ğŸš€ Startup and configuration loading
- ğŸ“‹ Processing status with progress indicators
- ğŸµ MP3 extraction and download status
- â­ Duplicate detection notifications
- âœ… Success confirmations
- âŒ Error messages with clear indicators
- ğŸ“Š Detailed summary statistics

### Debug Mode

For debugging, you can modify the script to add more verbose logging or run with Python's `-v` flag for detailed output.

## Version History

- **2.0.0** - Major update with hash-based duplicate detection, emoji-enhanced output, and simplified configuration
- **0.1.0** - Initial release with basic download and extraction functionality

## What's New in 2.0.0

- ğŸ” **Hash-based duplicate detection** - Automatically prevents re-downloading the same files
- ğŸ¨ **Rich emoji output** - Enhanced console experience with meaningful visual indicators
- â³ **Single-line progress** - Clean progress display that updates in place
- ğŸ§¹ **Automatic cleanup** - Always removes temporary files when MP3 downloading is enabled
- ğŸ“ **Smart filename generation** - Uses URL hashes for unique, consistent filenames
- âš¡ **No configuration needed** - Duplicate detection works out of the box
- ğŸ¯ **Simplified setup** - Removed complex database configuration options
